{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8eaacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc188ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "FORECAST_HORIZON = 28\n",
    "LOOKBACK_WINDOW = 56\n",
    "BATCH_SIZE = 32  # Small batch for memory efficiency\n",
    "EPOCHS = 30\n",
    "LEARNING_RATE = 0.0001\n",
    "D_MODEL = 64  # Model dimension (smaller for 8GB RAM)\n",
    "N_HEADS = 4\n",
    "E_LAYERS = 2  # Encoder layers\n",
    "D_LAYERS = 1  # Decoder layers\n",
    "D_FF = 128  # Feedforward dimension\n",
    "DROPOUT = 0.1\n",
    "AGGREGATION_LEVEL = 'store_category'\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44df4d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProbAttention(nn.Module):\n",
    "    \"\"\"ProbSparse Self-Attention (Informer's key innovation)\"\"\"\n",
    "    def __init__(self, mask_flag=True, factor=5, scale=None, attention_dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.factor = factor\n",
    "        self.scale = scale\n",
    "        self.mask_flag = mask_flag\n",
    "        self.dropout = nn.Dropout(attention_dropout)\n",
    "        \n",
    "    def _prob_QK(self, Q, K, sample_k, n_top):\n",
    "        \"\"\"ProbSparse sampling\"\"\"\n",
    "        B, H, L_K, E = K.shape\n",
    "        _, _, L_Q, _ = Q.shape\n",
    "        \n",
    "        # Sample K\n",
    "        K_expand = K.unsqueeze(-3).expand(B, H, L_Q, L_K, E)\n",
    "        index_sample = torch.randint(L_K, (L_Q, sample_k))\n",
    "        K_sample = K_expand[:, :, torch.arange(L_Q).unsqueeze(1), index_sample, :]\n",
    "        \n",
    "        # Calculate Q_K\n",
    "        Q_K_sample = torch.matmul(Q.unsqueeze(-2), K_sample.transpose(-2, -1)).squeeze(-2)\n",
    "        \n",
    "        # Find top queries\n",
    "        M = Q_K_sample.max(-1)[0] - torch.div(Q_K_sample.sum(-1), L_K)\n",
    "        M_top = M.topk(n_top, sorted=False)[1]\n",
    "        \n",
    "        return M_top\n",
    "    \n",
    "    def forward(self, queries, keys, values):\n",
    "        B, L_Q, H, D = queries.shape\n",
    "        _, L_K, _, _ = keys.shape\n",
    "        \n",
    "        queries = queries.transpose(1, 2)\n",
    "        keys = keys.transpose(1, 2)\n",
    "        values = values.transpose(1, 2)\n",
    "        \n",
    "        scale = self.scale or 1. / math.sqrt(D)\n",
    "        \n",
    "        # For cross-attention (L_Q != L_K), use full attention\n",
    "        if L_Q != L_K:\n",
    "            scores = torch.matmul(queries, keys.transpose(-2, -1)) * scale\n",
    "            attn = F.softmax(scores, dim=-1)\n",
    "            attn = self.dropout(attn)\n",
    "            context = torch.matmul(attn, values)\n",
    "            return context.transpose(1, 2).contiguous()\n",
    "        \n",
    "        # For self-attention, use ProbSparse\n",
    "        U_part = self.factor * np.ceil(np.log(L_K)).astype('int').item()\n",
    "        u = self.factor * np.ceil(np.log(L_Q)).astype('int').item()\n",
    "        \n",
    "        U_part = U_part if U_part < L_K else L_K\n",
    "        u = u if u < L_Q else L_Q\n",
    "        \n",
    "        # ProbSparse sampling\n",
    "        scores_top = self._prob_QK(queries, keys, sample_k=U_part, n_top=u)\n",
    "        \n",
    "        # Use mean of values as default context for non-selected queries\n",
    "        V_mean = values.mean(dim=2, keepdim=True).expand(-1, -1, L_Q, -1)\n",
    "        context = V_mean.clone()\n",
    "        \n",
    "        for i in range(B):\n",
    "            for j in range(H):\n",
    "                selected_Q = queries[i, j, scores_top[i, j], :]\n",
    "                attn = torch.matmul(selected_Q, keys[i, j].transpose(-2, -1))\n",
    "                attn = attn * scale\n",
    "                attn = F.softmax(attn, dim=-1)\n",
    "                attn = self.dropout(attn)\n",
    "                out = torch.matmul(attn, values[i, j])\n",
    "                context[i, j, scores_top[i, j], :] = out\n",
    "        \n",
    "        return context.transpose(1, 2).contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentionLayer(nn.Module):\n",
    "    \"\"\"Attention layer wrapper\"\"\"\n",
    "    def __init__(self, attention, d_model, n_heads, d_keys=None, d_values=None):\n",
    "        super().__init__()\n",
    "        d_keys = d_keys or (d_model // n_heads)\n",
    "        d_values = d_values or (d_model // n_heads)\n",
    "        \n",
    "        self.inner_attention = attention\n",
    "        self.query_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.key_projection = nn.Linear(d_model, d_keys * n_heads)\n",
    "        self.value_projection = nn.Linear(d_model, d_values * n_heads)\n",
    "        self.out_projection = nn.Linear(d_values * n_heads, d_model)\n",
    "        self.n_heads = n_heads\n",
    "        \n",
    "    def forward(self, queries, keys, values):\n",
    "        B, L, _ = queries.shape\n",
    "        _, S, _ = keys.shape\n",
    "        H = self.n_heads\n",
    "        \n",
    "        queries = self.query_projection(queries).view(B, L, H, -1)\n",
    "        keys = self.key_projection(keys).view(B, S, H, -1)\n",
    "        values = self.value_projection(values).view(B, S, H, -1)\n",
    "        \n",
    "        out = self.inner_attention(queries, keys, values)\n",
    "        out = out.view(B, L, -1)\n",
    "        \n",
    "        return self.out_projection(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b3d319",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    \"\"\"Informer Encoder Layer\"\"\"\n",
    "    def __init__(self, attention, d_model, d_ff=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.attention = attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        new_x = self.attention(x, x, x)\n",
    "        x = x + self.dropout(new_x)\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        y = x\n",
    "        y = self.dropout(F.relu(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        \n",
    "        return self.norm2(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a0bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    \"\"\"Informer Decoder Layer\"\"\"\n",
    "    def __init__(self, self_attention, cross_attention, d_model, d_ff=None, dropout=0.1):\n",
    "        super().__init__()\n",
    "        d_ff = d_ff or 4 * d_model\n",
    "        self.self_attention = self_attention\n",
    "        self.cross_attention = cross_attention\n",
    "        self.conv1 = nn.Conv1d(in_channels=d_model, out_channels=d_ff, kernel_size=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=d_ff, out_channels=d_model, kernel_size=1)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, cross):\n",
    "        x = x + self.dropout(self.self_attention(x, x, x))\n",
    "        x = self.norm1(x)\n",
    "        \n",
    "        x = x + self.dropout(self.cross_attention(x, cross, cross))\n",
    "        x = self.norm2(x)\n",
    "        \n",
    "        y = x\n",
    "        y = self.dropout(F.relu(self.conv1(y.transpose(-1, 1))))\n",
    "        y = self.dropout(self.conv2(y).transpose(-1, 1))\n",
    "        \n",
    "        return self.norm3(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113dd70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    \"\"\"Informer Encoder\"\"\"\n",
    "    def __init__(self, attn_layers, norm_layer=None):\n",
    "        super().__init__()\n",
    "        self.attn_layers = nn.ModuleList(attn_layers)\n",
    "        self.norm = norm_layer\n",
    "        \n",
    "    def forward(self, x):\n",
    "        for attn_layer in self.attn_layers:\n",
    "            x = attn_layer(x)\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05103c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    \"\"\"Informer Decoder\"\"\"\n",
    "    def __init__(self, layers, norm_layer=None):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList(layers)\n",
    "        self.norm = norm_layer\n",
    "        \n",
    "    def forward(self, x, cross):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, cross)\n",
    "        \n",
    "        if self.norm is not None:\n",
    "            x = self.norm(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2e83f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Informer(nn.Module):\n",
    "    \"\"\"Complete Informer Model\"\"\"\n",
    "    def __init__(self, enc_in, dec_in, c_out, seq_len, label_len, out_len,\n",
    "                 d_model=512, n_heads=8, e_layers=2, d_layers=1, d_ff=512, \n",
    "                 dropout=0.0, attn='prob', embed='fixed', freq='h', activation='gelu'):\n",
    "        super().__init__()\n",
    "        self.pred_len = out_len\n",
    "        self.label_len = label_len\n",
    "        self.seq_len = seq_len\n",
    "        \n",
    "        # Encoding\n",
    "        self.enc_embedding = nn.Linear(enc_in, d_model)\n",
    "        self.dec_embedding = nn.Linear(dec_in, d_model)\n",
    "        \n",
    "        # Positional encoding - separate for encoder and decoder\n",
    "        self.enc_position_encoding = nn.Parameter(torch.randn(1, seq_len, d_model))\n",
    "        self.dec_position_encoding = nn.Parameter(torch.randn(1, label_len + out_len, d_model))\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = Encoder(\n",
    "            [\n",
    "                EncoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        ProbAttention(False, attention_dropout=dropout),\n",
    "                        d_model, n_heads\n",
    "                    ),\n",
    "                    d_model, d_ff, dropout=dropout\n",
    "                ) for _ in range(e_layers)\n",
    "            ],\n",
    "            norm_layer=nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = Decoder(\n",
    "            [\n",
    "                DecoderLayer(\n",
    "                    AttentionLayer(\n",
    "                        ProbAttention(True, attention_dropout=dropout),\n",
    "                        d_model, n_heads\n",
    "                    ),\n",
    "                    AttentionLayer(\n",
    "                        ProbAttention(False, attention_dropout=dropout),\n",
    "                        d_model, n_heads\n",
    "                    ),\n",
    "                    d_model, d_ff, dropout=dropout\n",
    "                ) for _ in range(d_layers)\n",
    "            ],\n",
    "            norm_layer=nn.LayerNorm(d_model)\n",
    "        )\n",
    "        \n",
    "        # Projection\n",
    "        self.projection = nn.Linear(d_model, c_out, bias=True)\n",
    "        \n",
    "    def forward(self, x_enc, x_dec):\n",
    "        # Encoding\n",
    "        enc_out = self.enc_embedding(x_enc)\n",
    "        enc_out = enc_out + self.enc_position_encoding[:, :x_enc.size(1), :]\n",
    "        enc_out = self.encoder(enc_out)\n",
    "        \n",
    "        # Decoding\n",
    "        dec_out = self.dec_embedding(x_dec)\n",
    "        dec_out = dec_out + self.dec_position_encoding[:, :x_dec.size(1), :]\n",
    "        dec_out = self.decoder(dec_out, enc_out)\n",
    "        dec_out = self.projection(dec_out)\n",
    "        \n",
    "        return dec_out[:, -self.pred_len:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbb5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InformerDataset(Dataset):\n",
    "    \"\"\"Dataset for Informer with encoder-decoder structure\"\"\"\n",
    "    def __init__(self, data, seq_len, label_len, pred_len, train=True):\n",
    "        self.data = data\n",
    "        self.seq_len = seq_len\n",
    "        self.label_len = label_len\n",
    "        self.pred_len = pred_len\n",
    "        self.train = train\n",
    "        \n",
    "        self.X_enc = []\n",
    "        self.X_dec = []\n",
    "        self.y = []\n",
    "        \n",
    "        total_len = seq_len + pred_len\n",
    "        for i in range(len(data) - total_len + 1):\n",
    "            # Encoder input: historical data\n",
    "            self.X_enc.append(data[i:i+seq_len])\n",
    "            \n",
    "            # Decoder input: last label_len of encoder + zeros for prediction\n",
    "            dec_input = np.concatenate([\n",
    "                data[i+seq_len-label_len:i+seq_len],\n",
    "                np.zeros((pred_len, data.shape[1]))\n",
    "            ], axis=0)\n",
    "            self.X_dec.append(dec_input)\n",
    "            \n",
    "            # Target: future values\n",
    "            if train:\n",
    "                self.y.append(data[i+seq_len:i+seq_len+pred_len])\n",
    "        \n",
    "        self.X_enc = np.array(self.X_enc, dtype=np.float32)\n",
    "        self.X_dec = np.array(self.X_dec, dtype=np.float32)\n",
    "        if train:\n",
    "            self.y = np.array(self.y, dtype=np.float32)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X_enc)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.train:\n",
    "            return (torch.FloatTensor(self.X_enc[idx]), \n",
    "                    torch.FloatTensor(self.X_dec[idx]), \n",
    "                    torch.FloatTensor(self.y[idx]))\n",
    "        else:\n",
    "            return (torch.FloatTensor(self.X_enc[idx]), \n",
    "                    torch.FloatTensor(self.X_dec[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fde0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sales = pd.read_csv('sales_train_validation.csv')\n",
    "calendar = pd.read_csv('calendar.csv')\n",
    "\n",
    "day_cols = [col for col in sales.columns if col.startswith('d_')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1ffb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_aggregated_series(sales_df, level):\n",
    "    if level == 'store_category':\n",
    "        group_cols = ['store_id', 'cat_id']\n",
    "    elif level == 'store':\n",
    "        group_cols = ['store_id']\n",
    "    elif level == 'category':\n",
    "        group_cols = ['cat_id']\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown level: {level}\")\n",
    "    \n",
    "    agg_sales = sales_df.groupby(group_cols)[day_cols].sum().reset_index()\n",
    "    \n",
    "    if len(group_cols) > 1:\n",
    "        agg_sales['series_id'] = agg_sales[group_cols].apply(lambda x: '_'.join(x), axis=1)\n",
    "    else:\n",
    "        agg_sales['series_id'] = agg_sales[group_cols[0]]\n",
    "    \n",
    "    return agg_sales\n",
    "\n",
    "agg_sales = create_aggregated_series(sales, AGGREGATION_LEVEL)\n",
    "n_series = len(agg_sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea245d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "series_results = []\n",
    "\n",
    "LABEL_LEN = FORECAST_HORIZON // 2  # Half of pred_len for label_len\n",
    "\n",
    "for idx, row in agg_sales.iterrows():\n",
    "    series_id = row['series_id']\n",
    "    print(f\"\\n   [{idx+1}/{n_series}] Training {series_id}...\")\n",
    "    \n",
    "    # Get time series\n",
    "    ts_data = np.array([row[col] for col in day_cols], dtype=np.float32)\n",
    "    \n",
    "    # Normalize\n",
    "    scaler = StandardScaler()\n",
    "    ts_data_scaled = scaler.fit_transform(ts_data.reshape(-1, 1))\n",
    "    \n",
    "    # Split train/val\n",
    "    train_data = ts_data_scaled[:-FORECAST_HORIZON]\n",
    "    val_data = ts_data_scaled\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = InformerDataset(\n",
    "        train_data, LOOKBACK_WINDOW, LABEL_LEN, FORECAST_HORIZON, train=True\n",
    "    )\n",
    "    \n",
    "    if len(train_dataset) < BATCH_SIZE:\n",
    "        print(f\"      Warning: Not enough data for {series_id}, skipping...\")\n",
    "        continue\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    \n",
    "    # Initialize model\n",
    "    model = Informer(\n",
    "        enc_in=1, dec_in=1, c_out=1,\n",
    "        seq_len=LOOKBACK_WINDOW,\n",
    "        label_len=LABEL_LEN,\n",
    "        out_len=FORECAST_HORIZON,\n",
    "        d_model=D_MODEL,\n",
    "        n_heads=N_HEADS,\n",
    "        e_layers=E_LAYERS,\n",
    "        d_layers=D_LAYERS,\n",
    "        d_ff=D_FF,\n",
    "        dropout=DROPOUT\n",
    "    ).to(device)\n",
    "    \n",
    "    # Loss and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    \n",
    "    # Training loop\n",
    "    model.train()\n",
    "    best_loss = float('inf')\n",
    "    patience = 5\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch_loss = 0\n",
    "        for batch_x_enc, batch_x_dec, batch_y in train_loader:\n",
    "            batch_x_enc = batch_x_enc.to(device)\n",
    "            batch_x_dec = batch_x_dec.to(device)\n",
    "            batch_y = batch_y.to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_x_enc, batch_x_dec)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        avg_loss = epoch_loss / len(train_loader)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f\"      Epoch {epoch+1}/{EPOCHS}, Loss: {avg_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_loss < best_loss:\n",
    "            best_loss = avg_loss\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(f\"      Early stopping at epoch {epoch+1}\")\n",
    "                break\n",
    "    \n",
    "    # Validation prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Create validation input\n",
    "        val_enc = torch.FloatTensor(train_data[-LOOKBACK_WINDOW:]).unsqueeze(0).to(device)\n",
    "        val_dec = torch.FloatTensor(\n",
    "            np.concatenate([\n",
    "                train_data[-LABEL_LEN:],\n",
    "                np.zeros((FORECAST_HORIZON, 1))\n",
    "            ], axis=0)\n",
    "        ).unsqueeze(0).to(device)\n",
    "        \n",
    "        prediction_scaled = model(val_enc, val_dec).cpu().numpy().squeeze()\n",
    "    \n",
    "    # Denormalize\n",
    "    prediction = scaler.inverse_transform(prediction_scaled.reshape(-1, 1)).flatten()\n",
    "    prediction = np.maximum(prediction, 0)\n",
    "    \n",
    "    # Get actual values\n",
    "    actual = ts_data[-FORECAST_HORIZON:]\n",
    "    \n",
    "    # Calculate metrics\n",
    "    rmse = np.sqrt(mean_squared_error(actual, prediction))\n",
    "    mae = mean_absolute_error(actual, prediction)\n",
    "    \n",
    "    print(f\"      âœ“ RMSE: {rmse:.2f}, MAE: {mae:.2f}\")\n",
    "    \n",
    "    # Store results\n",
    "    models[series_id] = {'model': model, 'scaler': scaler}\n",
    "    series_results.append({\n",
    "        'series_id': series_id,\n",
    "        'rmse': rmse,\n",
    "        'mae': mae,\n",
    "        'predictions': prediction,\n",
    "        'actuals': actual\n",
    "    })\n",
    "    \n",
    "    # Clear memory\n",
    "    del model, train_dataset, train_loader\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "assignment2",
   "language": "python",
   "name": "assignment2"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
